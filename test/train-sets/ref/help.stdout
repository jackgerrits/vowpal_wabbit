driver:
  --onethread           Disable parse thread
VW options:
  --ring_size arg (=256, ) size of example ring
  --strict_parse           throw on malformed examples
Update options:
  -l [ --learning_rate ] arg Set learning rate
  --power_t arg              t power value
  --decay_learning_rate arg  Set Decay factor for learning_rate between passes
  --initial_t arg            initial t value
  --feature_mask arg         Use existing regressor to determine which 
                             parameters may be updated.  If no 
                             initial_regressor given, also used for initial 
                             weights.
Weight options:
  -i [ --initial_regressor ] arg  Initial regressor(s)
  --initial_weight arg            Set all weights to an initial value of arg.
  --random_weights                make initial weights random
  --normal_weights                make initial weights normal
  --truncated_normal_weights      make initial weights truncated normal
  --sparse_weights                Use a sparse datastructure for weights
  --input_feature_regularizer arg Per feature regularization input file
Diagnostic options:
  --version             Version information
  -a [ --audit ]        print weights of features
  -P [ --progress ] arg Progress update frequency. int: additive, float: 
                        multiplicative
  --quiet               Don't output disgnostics and progress updates
  --dry_run             Parse arguments and print corresponding metadata. Will 
                        not execute driver.
  -h [ --help ]         More information on vowpal wabbit can be found here 
                        https://vowpalwabbit.org.
Randomization options:
  --random_seed arg     seed random number generator
Feature options:
  --hash arg                      how to hash the features. Available options: 
                                  strings, all
  --hash_seed arg (=0, )          seed for hash function
  --ignore arg                    ignore namespaces beginning with character 
                                  <arg>
  --ignore_linear arg             ignore namespaces beginning with character 
                                  <arg> for linear terms only
  --keep arg                      keep namespaces beginning with character 
                                  <arg>
  --redefine arg                  redefine namespaces beginning with characters
                                  of std::string S as namespace N. <arg> shall 
                                  be in form 'N:=S' where := is operator. Empty
                                  N or S are treated as default namespace. Use 
                                  ':' as a wildcard in S.
  -b [ --bit_precision ] arg      number of bits in the feature table
  --noconstant                    Don't add a constant feature
  -C [ --constant ] arg           Set initial value of constant
  --ngram arg                     Generate N grams. To generate N grams for a 
                                  single namespace 'foo', arg should be fN.
  --skips arg                     Generate skips in N grams. This in 
                                  conjunction with the ngram tag can be used to
                                  generate generalized n-skip-k-gram. To 
                                  generate n-skips for a single namespace 
                                  'foo', arg should be fN.
  --feature_limit arg             limit to N features. To apply to a single 
                                  namespace 'foo', arg should be fN
  --affix arg                     generate prefixes/suffixes of features; 
                                  argument '+2a,-3b,+1' means generate 2-char 
                                  prefixes for namespace a, 3-char suffixes for
                                  b and 1 char prefixes for default namespace
  --spelling arg                  compute spelling features for a give 
                                  namespace (use '_' for default namespace)
  --dictionary arg                read a dictionary for additional features 
                                  (arg either 'x:file' or just 'file')
  --dictionary_path arg           look in this directory for dictionaries; 
                                  defaults to current directory or env{PATH}
  --interactions arg              Create feature interactions of any level 
                                  between namespaces.
  --permutations                  Use permutations instead of combinations for 
                                  feature interactions of same namespace.
  --leave_duplicate_interactions  Don't remove interactions with duplicate 
                                  combinations of namespaces. For ex. this is a
                                  duplicate: '-q ab -q ba' and a lot more in 
                                  '-q ::'.
  -q [ --quadratic ] arg          Create and use quadratic features
  --q: arg                        DEPRECATED ':' corresponds to a wildcard for 
                                  all printable characters
  --cubic arg                     Create and use cubic features
Example options:
  -t [ --testonly ]                Ignore label information and just test
  --holdout_off                    no holdout data in multiple passes
  --holdout_period arg (=10, )     holdout period for test only
  --holdout_after arg              holdout after n training examples, default 
                                   off (disables holdout_period)
  --early_terminate arg (=3, )     Specify the number of passes tolerated when 
                                   holdout loss doesn't decrease before early 
                                   termination
  --passes arg                     Number of Training Passes
  --initial_pass_length arg        initial number of examples per pass
  --examples arg                   number of examples to parse
  --min_prediction arg             Smallest prediction to output
  --max_prediction arg             Largest prediction to output
  --sort_features                  turn this on to disregard order in which 
                                   features have been defined. This will lead 
                                   to smaller cache sizes
  --loss_function arg (=squared, ) Specify the loss function to be used, uses 
                                   squared by default. Currently available ones
                                   are squared, classic, hinge, logistic, 
                                   quantile and poisson.
  --quantile_tau arg (=0.5, )      Parameter \tau associated with Quantile 
                                   loss. Defaults to 0.5
  --l1 arg                         l_1 lambda
  --l2 arg                         l_2 lambda
  --no_bias_regularization         no bias in regularization
Output model:
  -f [ --final_regressor ] arg          Final regressor
  --readable_model arg                  Output human-readable final regressor 
                                        with numeric features
  --invert_hash arg                     Output human-readable final regressor 
                                        with feature names.  Computationally 
                                        expensive.
  --save_resume                         save extra state so learning can be 
                                        resumed later with new data
  --preserve_performance_counters       reset performance counters when 
                                        warmstarting
  --save_per_pass                       Save the model after every pass over 
                                        data
  --output_feature_regularizer_binary arg
                                        Per feature regularization output file
  --output_feature_regularizer_text arg Per feature regularization output file,
                                        in text
  --id arg                              User supplied ID embedded into the 
                                        final regressor
Output options:
  -p [ --predictions ] arg     File to output predictions to
  -r [ --raw_predictions ] arg File to output unnormalized predictions to
Input options:
  -d [ --data ] arg     Example set
  --port arg            port to listen on; use 0 to pick unused port
  --pid_file arg        Write pid file in persistent daemon mode
  -c [ --cache ]        Use a cache.  The default is <data>.cache
  --cache_file arg      The location(s) of cache_file.
  --json                Enable JSON parsing.
  --dsjson              Enable Decision Service JSON parsing.
  -k [ --kill_cache ]   do not reuse existing cache: create a new one always
  --compressed          use gzip format whenever possible. If a cache file is 
                        being created, this option creates a compressed cache 
                        file. A mixture of raw-text & compressed inputs are 
                        supported with autodetection.
  --no_stdin            do not default to reading from stdin
  --chain_hash          Enable chain hash in JSON for feature name and string 
                        feature value. e.g. {'A': {'B': 'C'}} is hashed as 
                        A^B^C. Note: this will become the default in a future 
                        version, so enabling this option will migrate you to 
                        the new behavior and silence the warning.
  --flatbuffer          data file will be interpreted as a flatbuffer file
Binary loss:
  --binary              report loss as binary classification on -1,1
Continuous actions tree with smoothing:
  --cats arg            number of discrete actions <k> for cats
  --min_value arg       Minimum continuous value
  --max_value arg       Maximum continuous value
  --bandwidth arg       Bandwidth (radius) of randomization around discrete 
                        actions in terms of continuous range. By default will 
                        be set to half of the continuous action unit-range 
                        resulting in smoothing that stays inside the action 
                        space unit-range:
                        unit_range = (max_value - min_value)/num-of-actions
                        default bandwidth = unit_range / 2.0
Continuous action tree with smoothing with full pdf:
  --cats_pdf arg        number of tree labels <k> for cats_pdf
CATS Tree Options:
  --cats_tree arg             CATS Tree with <k> labels
  --tree_bandwidth arg (=0, ) tree bandwidth for continuous actions in terms of
                              #actions
  --link arg                  Specify the link function: identity, logistic, 
                              glf1 or poisson
Contextual Bandit Options:
  --cb arg              Use contextual bandit learning with <k> costs
  --cb_type arg         contextual bandit method to use in {ips,dm,dr}
  --eval                Evaluate a policy rather than optimizing.
  --cb_force_legacy     Default to non-adf cb implementation (cb_to_cb_adf)
Contextual Bandit with Action Dependent Features:
  --cb_adf              Do Contextual Bandit learning with multiline action 
                        dependent features.
  --rank_all            Return actions sorted by score order
  --no_predict          Do not do a prediction when training
  --clip_p arg (=0, )   Clipping probability in importance weight. Default: 0.f
                        (no clipping).
  --cb_type arg         contextual bandit method to use in {ips, dm, dr, mtr, 
                        sm}. Default: mtr
CB Distributionally Robust Optimization:
  --cb_dro                     Use DRO for cb learning
  --cb_dro_alpha arg (=0.05, ) Confidence level for cb dro
  --cb_dro_tau arg (=0.999, )  Time constant for count decay for cb dro
  --cb_dro_wmax arg (=inf, )   maximum importance weight for cb_dro
Contextual Bandit Exploration:
  --cb_explore arg        Online explore-exploit for a <k> action contextual 
                          bandit problem
  --first arg             tau-first exploration
  --epsilon arg (=0.05, ) epsilon-greedy exploration
  --bag arg               bagging-based exploration
  --cover arg             Online cover based exploration
  --nounif                do not explore uniformly on zero-probability actions 
                          in cover
  --psi arg (=1, )        disagreement parameter for cover
Contextual Bandit Exploration with ADF (bagging):
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem 
                        with multiline action dependent features
  --epsilon arg         epsilon-greedy exploration
  --bag arg             bagging-based exploration
  --greedify            always update first policy once in bagging
  --first_only          Only explore the first action in a tie-breaking event
Contextual Bandit Exploration with ADF (online cover):
  --cb_explore_adf        Online explore-exploit for a contextual bandit 
                          problem with multiline action dependent features
  --cover arg             Online cover based exploration
  --psi arg (=1, )        disagreement parameter for cover
  --nounif                do not explore uniformly on zero-probability actions 
                          in cover
  --first_only            Only explore the first action in a tie-breaking event
  --cb_type arg           contextual bandit method to use in {ips,dr,mtr}. 
                          Default: mtr
  --epsilon arg (=0.05, ) epsilon-greedy exploration
Contextual Bandit Exploration with ADF (tau-first):
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem 
                        with multiline action dependent features
  --first arg           tau-first exploration
  --epsilon arg         epsilon-greedy exploration
Contextual Bandit Exploration with ADF (greedy):
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem 
                        with multiline action dependent features
  --epsilon arg         epsilon-greedy exploration
  --first_only          Only explore the first action in a tie-breaking event
Contextual Bandit Exploration with ADF (RegCB):
  --cb_explore_adf          Online explore-exploit for a contextual bandit 
                            problem with multiline action dependent features
  --regcb                   RegCB-elim exploration
  --regcbopt                RegCB optimistic exploration
  --mellowness arg (=0.1, ) RegCB mellowness parameter c_0. Default 0.1
  --cb_min_cost arg (=0, )  lower bound on cost
  --cb_max_cost arg (=1, )  upper bound on cost
  --first_only              Only explore the first action in a tie-breaking 
                            event
  --cb_type arg             contextual bandit method to use in {ips,dr,mtr}. 
                            Default: mtr
Contextual Bandit Exploration with ADF (rnd):
  --cb_explore_adf             Online explore-exploit for a contextual bandit 
                               problem with multiline action dependent features
  --epsilon arg                minimum exploration probability
  --rnd arg                    rnd based exploration
  --rnd_alpha arg (=0.1, )     ci width for rnd (bigger => more exploration on 
                               repeating features)
  --rnd_invlambda arg (=0.1, ) covariance regularization strength rnd (bigger 
                               => more exploration on new features)
Contextual Bandit Exploration with ADF (softmax):
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem 
                        with multiline action dependent features
  --epsilon arg         epsilon-greedy exploration
  --softmax             softmax exploration
  --lambda arg (=1, )   parameter for softmax
Contextual Bandit Exploration with ADF (SquareCB):
  --cb_explore_adf              Online explore-exploit for a contextual bandit 
                                problem with multiline action dependent 
                                features
  --squarecb                    SquareCB exploration
  --gamma_scale arg (=10, )     Sets SquareCB greediness parameter to 
                                gamma=[gamma_scale]*[num examples]^1/2
  --gamma_exponent arg (=0.5, ) Exponent on [num examples] in SquareCB 
                                greediness parameter gamma.
  --elim                        Only perform SquareCB exploration over 
                                plausible actions (computed via RegCB strategy)
  --mellowness arg (=0.001, )   Mellowness parameter c_0 for computing 
                                plausible action set. Only used with --elim
  --cb_min_cost arg (=0, )      Lower bound on cost. Only used with --elim
  --cb_max_cost arg (=1, )      Upper bound on cost. Only used with --elim
  --cb_type arg                 contextual bandit method to use in 
                                {ips,dr,mtr}. Default: mtr
Contextual Bandit Exploration with ADF (synthetic cover):
  --cb_explore_adf              Online explore-exploit for a contextual bandit 
                                problem with multiline action dependent 
                                features
  --epsilon arg                 epsilon-greedy exploration
  --synthcover                  use synthetic cover exploration
  --synthcoverpsi arg (=0.1, )  exploration reward bonus
  --synthcoversize arg (=100, ) number of policies in cover
Continuous actions - cb_explore_pdf:
  --cb_explore_pdf        Sample a pdf and pick a continuous valued action
  --epsilon arg (=0.05, ) epsilon-greedy exploration
  --min_value arg (=0, )  min value for continuous range
  --max_value arg (=1, )  max value for continuous range
  --first_only            Use user provided first action or user provided pdf 
                          or uniform random
CB Sample:
  --cb_sample           Sample from CB pdf and swap top action.
Contextual Bandit Options: cb -> cb_adf:
  --cb_to_cbadf arg     Maps cb_adf to cb. Disable with cb_force_legacy.
  --cb arg              Maps cb_adf to cb. Disable with cb_force_legacy.
  --cb_explore arg      Translate cb explore to cb_explore_adf. Disable with 
                        cb_force_legacy.
  --cbify arg           Translate cbify to cb_adf. Disable with 
                        cb_force_legacy.
  --cb_type arg         contextual bandit method to use in {}
  --cb_force_legacy     Default to non-adf cb implementation (cb_algs)
Make Multiclass into Contextual Bandit:
  --cbify arg                  Convert multiclass on <k> classes into a 
                               contextual bandit problem
  --cbify_cs                   Consume cost-sensitive classification examples 
                               instead of multiclass
  --cbify_reg                  Consume regression examples instead of 
                               multiclass and cost sensitive
  --cats arg (=0, )            Continuous action tree with smoothing
  --cb_discrete                Discretizes continuous space and adds cb_explore
                               as option
  --min_value arg              Minimum continuous value
  --max_value arg              Maximum continuous value
  --loss_option arg (=0, )     loss options for regression - 0:squared, 
                               1:absolute, 2:0/1
  --loss_report arg (=0, )     loss report option - 0:normalized, 
                               1:denormalized
  --loss_01_ratio arg (=0.1, ) ratio of zero loss for 0/1 loss
  --loss0 arg (=0, )           loss for correct label
  --loss1 arg (=1, )           loss for incorrect label
Make csoaa_ldf into Contextual Bandit:
  --cbify_ldf           Convert csoaa_ldf into a contextual bandit problem
  --loss0 arg (=0, )    loss for correct label
  --loss1 arg (=1, )    loss for incorrect label
EXPERIMENTAL: Conditional Contextual Bandit Exploration with ADF:
  --ccb_explore_adf               EXPERIMENTAL: Do Conditional Contextual 
                                  Bandit learning with multiline action 
                                  dependent features.
  --all_slots_loss                Report average loss from all slots
  --leave_duplicate_interactions  Don't remove interactions with duplicate 
                                  combinations of namespaces. For ex. this is a
                                  duplicate: '-q ab -q ba' and a lot more in 
                                  '-q ::'.
Cost Sensitive One Against All:
  --csoaa arg           One-against-all multiclass with <k> costs
Cost Sensitive One Against All with Label Dependent Features:
  --csoaa_ldf arg       Use one-against-all multiclass learning with label 
                        dependent features.
  --ldf_override arg    Override singleline or multiline from csoaa_ldf or 
                        wap_ldf, eg if stored in file
  --csoaa_rank          Return actions sorted by score order
  --probabilities       predict probabilites of all classes
Cost Sensitive weighted all-pairs with Label Dependent Features:
  --wap_ldf arg         Use weighted all-pairs multiclass learning with label 
                        dependent features.  Specify singleline or multiline.
Explore evaluation:
  --explore_eval        Evaluate explore_eval adf policies
  --multiplier arg      Multiplier used to make all rejection sample 
                        probabilities <= 1
Debug: Metrics:
  --extra_metrics arg   Specify filename to write metrics to. Note: There is no
                        fixed schema.
Follow the Regularized Leader:
  --ftrl                FTRL: Follow the Proximal Regularized Leader
  --coin                Coin betting optimizer
  --pistol              PiSTOL: Parameter-free STOchastic Learning
  --ftrl_alpha arg      Learning rate for FTRL optimization
  --ftrl_beta arg       Learning rate for FTRL optimization
Gradient Descent options:
  --sgd                  use regular stochastic gradient descent update.
  --adaptive             use adaptive, individual learning rates.
  --adax                 use adaptive learning rates with x^2 instead of g^2x^2
  --invariant            use safe/importance aware updates.
  --normalized           use per feature normalized updates
  --sparse_l2 arg (=0, ) use per feature normalized updates
  --l1_state arg (=0, )  use per feature normalized updates
  --l2_state arg (=1, )  use per feature normalized updates
Generate interactions:
  --leave_duplicate_interactions  Don't remove interactions with duplicate 
                                  combinations of namespaces. For ex. this is a
                                  duplicate: '-q ab -q ba' and a lot more in 
                                  '-q ::'.
Continuous actions - convert to pmf:
  --get_pmf             Convert a single multiclass prediction to a pmf
Offset tree Options:
  --ot arg              Offset tree with <k> labels
Convert discrete PMF into continuous PDF:
  --pmf_to_pdf arg (=0, ) number of discrete actions <k> for pmf_to_pdf
  --min_value arg         Minimum continuous value
  --max_value arg         Maximum continuous value
  --bandwidth arg         Bandwidth (radius) of randomization around discrete 
                          actions in terms of continuous range. By default will
                          be set to half of the continuous action unit-range 
                          resulting in smoothing that stays inside the action 
                          space unit-range:
                          unit_range = (max_value - min_value)/num-of-actions
                          default bandwidth = unit_range / 2.0
  --first_only            Use user provided first action or user provided pdf 
                          or uniform random
Continuous actions - sample pdf:
  --sample_pdf          Sample a pdf and pick a continuous valued action
scorer options:
  --link arg (=identity, ) Specify the link function: identity, logistic, glf1 
                           or poisson
Slates:
  --slates              EXPERIMENTAL
Make Multiclass into Warm-starting Contextual Bandit:
  --warm_cb arg                        Convert multiclass on <k> classes into a
                                       contextual bandit problem
  --warm_cb_cs                         consume cost-sensitive classification 
                                       examples instead of multiclass
  --loss0 arg (=0, )                   loss for correct label
  --loss1 arg (=1, )                   loss for incorrect label
  --warm_start arg (=0, )              number of training examples for warm 
                                       start phase
  --epsilon arg                        epsilon-greedy exploration
  --interaction arg (=4294967295, )    number of examples for the interactive 
                                       contextual bandit learning phase
  --warm_start_update                  indicator of warm start updates
  --interaction_update                 indicator of interaction updates
  --corrupt_type_warm_start arg (=1, ) type of label corruption in the warm 
                                       start phase (1: uniformly at random, 2: 
                                       circular, 3: replacing with overwriting 
                                       label)
  --corrupt_prob_warm_start arg (=0, ) probability of label corruption in the 
                                       warm start phase
  --choices_lambda arg (=1, )          the number of candidate lambdas to 
                                       aggregate (lambda is the importance 
                                       weight parameter between the two 
                                       sources)
  --lambda_scheme arg (=1, )           The scheme for generating candidate 
                                       lambda set (1: center lambda=0.5, 2: 
                                       center lambda=0.5, min lambda=0, max 
                                       lambda=1, 3: center lambda=epsilon/(1+ep
                                       silon), 4: center lambda=epsilon/(1+epsi
                                       lon), min lambda=0, max lambda=1); the 
                                       rest of candidate lambda values are 
                                       generated using a doubling scheme
  --overwrite_label arg (=1, )         the label used by type 3 corruptions 
                                       (overwriting)
  --sim_bandit                         simulate contextual bandit updates on 
                                       warm start examples
