creating features for following interactions: abc 
final_regressor = models/xxor.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/xxor.dat.cache
Reading datafile = train-sets/xxor.dat
num sources = 1
Enabled reductions: gd, scorer
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000        5
0.581535 0.163071            2            2.0   0.0000   0.4038        5
0.422720 0.105088            3            3.0   0.0000   0.3242        5
0.567040 1.000000            4            4.0   1.0000   0.0000        5
0.527990 0.449890            6            6.0   1.0000   0.1234        5
0.493866 0.391496            8            8.0   0.0000   0.6019        5
0.407024 0.175444           11           11.0   0.0000   0.4429        5
0.361112 0.234854           15           15.0   1.0000   0.5645        5
0.304275 0.133764           20           20.0   1.0000   0.5957        5
0.249202 0.091851           27           27.0   0.0000   0.2644        5
0.201721 0.059280           36           36.0   1.0000   0.7710        5
0.158984 0.030773           48           48.0   0.0000   0.1478        5
0.122698 0.013839           64           64.0   0.0000   0.0883        5
0.092575 0.004943           86           86.0   1.0000   0.9496        5
0.069532 0.001197          115          115.0   0.0000   0.0223        5
0.051971 0.000188          154          154.0   0.0000   0.0084        5
0.038856 0.000016          206          206.0   1.0000   0.9988        5
0.029107 0.000001          275          275.0   0.0000   0.0002        5
0.021810 0.000000          367          367.0   1.0000   1.0000        5
0.016335 0.000000          490          490.0   0.0000   0.0000        5
0.012239 0.000000          654          654.0   1.0000   1.0000        5

finished run
number of examples per pass = 8
passes used = 100
weighted example sum = 800.000000
weighted label sum = 400.000000
average loss = 0.010005
best constant = 0.500000
best constant's loss = 0.250000
total feature number = 4000
