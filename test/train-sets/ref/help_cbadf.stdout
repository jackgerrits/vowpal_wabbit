driver:
  --onethread           Disable parse thread
VW options:
  --ring_size arg (=256, ) size of example ring
  --strict_parse           throw on malformed examples
Update options:
  -l [ --learning_rate ] arg Set learning rate
  --power_t arg              t power value
  --decay_learning_rate arg  Set Decay factor for learning_rate between passes
  --initial_t arg            initial t value
  --feature_mask arg         Use existing regressor to determine which 
                             parameters may be updated.  If no 
                             initial_regressor given, also used for initial 
                             weights.
Weight options:
  -i [ --initial_regressor ] arg  Initial regressor(s)
  --initial_weight arg            Set all weights to an initial value of arg.
  --random_weights                make initial weights random
  --normal_weights                make initial weights normal
  --truncated_normal_weights      make initial weights truncated normal
  --sparse_weights                Use a sparse datastructure for weights
  --input_feature_regularizer arg Per feature regularization input file
Diagnostic options:
  --version             Version information
  -a [ --audit ]        print weights of features
  -P [ --progress ] arg Progress update frequency. int: additive, float: 
                        multiplicative
  --quiet               Don't output disgnostics and progress updates
  --dry_run             Parse arguments and print corresponding metadata. Will 
                        not execute driver.
  -h [ --help ]         More information on vowpal wabbit can be found here 
                        https://vowpalwabbit.org.
Randomization options:
  --random_seed arg     seed random number generator
Feature options:
  --hash arg                      how to hash the features. Available options: 
                                  strings, all
  --hash_seed arg (=0, )          seed for hash function
  -b [ --bit_precision ] arg      number of bits in the feature table
  --noconstant                    Don't add a constant feature
  -C [ --constant ] arg           Set initial value of constant
  --interactions arg              Create feature interactions of any level 
                                  between namespaces.
  --permutations                  Use permutations instead of combinations for 
                                  feature interactions of same namespace.
  --leave_duplicate_interactions  Don't remove interactions with duplicate 
                                  combinations of namespaces. For ex. this is a
                                  duplicate: '-q ab -q ba' and a lot more in 
                                  '-q ::'.
Example options:
  -t [ --testonly ]                Ignore label information and just test
  --holdout_off                    no holdout data in multiple passes
  --holdout_period arg (=10, )     holdout period for test only
  --holdout_after arg              holdout after n training examples, default 
                                   off (disables holdout_period)
  --early_terminate arg (=3, )     Specify the number of passes tolerated when 
                                   holdout loss doesn't decrease before early 
                                   termination
  --passes arg                     Number of Training Passes
  --initial_pass_length arg        initial number of examples per pass
  --examples arg                   number of examples to parse
  --min_prediction arg             Smallest prediction to output
  --max_prediction arg             Largest prediction to output
  --sort_features                  turn this on to disregard order in which 
                                   features have been defined. This will lead 
                                   to smaller cache sizes
  --loss_function arg (=squared, ) Specify the loss function to be used, uses 
                                   squared by default. Currently available ones
                                   are squared, classic, hinge, logistic, 
                                   quantile and poisson.
  --quantile_tau arg (=0.5, )      Parameter \tau associated with Quantile 
                                   loss. Defaults to 0.5
  --l1 arg                         l_1 lambda
  --l2 arg                         l_2 lambda
  --no_bias_regularization         no bias in regularization
Output model:
  -f [ --final_regressor ] arg          Final regressor
  --readable_model arg                  Output human-readable final regressor 
                                        with numeric features
  --invert_hash arg                     Output human-readable final regressor 
                                        with feature names.  Computationally 
                                        expensive.
  --save_resume                         save extra state so learning can be 
                                        resumed later with new data
  --preserve_performance_counters       reset performance counters when 
                                        warmstarting
  --save_per_pass                       Save the model after every pass over 
                                        data
  --output_feature_regularizer_binary arg
                                        Per feature regularization output file
  --output_feature_regularizer_text arg Per feature regularization output file,
                                        in text
  --id arg                              User supplied ID embedded into the 
                                        final regressor
Output options:
  -p [ --predictions ] arg     File to output predictions to
  -r [ --raw_predictions ] arg File to output unnormalized predictions to
Input options:
  -d [ --data ] arg     Example set
  --port arg            port to listen on; use 0 to pick unused port
  --pid_file arg        Write pid file in persistent daemon mode
  -c [ --cache ]        Use a cache.  The default is <data>.cache
  --cache_file arg      The location(s) of cache_file.
  --json                Enable JSON parsing.
  --dsjson              Enable Decision Service JSON parsing.
  -k [ --kill_cache ]   do not reuse existing cache: create a new one always
  --compressed          use gzip format whenever possible. If a cache file is 
                        being created, this option creates a compressed cache 
                        file. A mixture of raw-text & compressed inputs are 
                        supported with autodetection.
  --no_stdin            do not default to reading from stdin
  --chain_hash          Enable chain hash in JSON for feature name and string 
                        feature value. e.g. {'A': {'B': 'C'}} is hashed as 
                        A^B^C. Note: this will become the default in a future 
                        version, so enabling this option will migrate you to 
                        the new behavior and silence the warning.
  --flatbuffer          data file will be interpreted as a flatbuffer file
Gradient Descent options:
  --sgd                  use regular stochastic gradient descent update.
  --adaptive             use adaptive, individual learning rates.
  --adax                 use adaptive learning rates with x^2 instead of g^2x^2
  --invariant            use safe/importance aware updates.
  --normalized           use per feature normalized updates
  --sparse_l2 arg (=0, ) use per feature normalized updates
  --l1_state arg (=0, )  use per feature normalized updates
  --l2_state arg (=1, )  use per feature normalized updates
scorer options:
  --link arg (=identity, ) Specify the link function: identity, logistic, glf1 
                           or poisson
Cost Sensitive One Against All with Label Dependent Features:
  --csoaa_ldf arg       Use one-against-all multiclass learning with label 
                        dependent features.
  --ldf_override arg    Override singleline or multiline from csoaa_ldf or 
                        wap_ldf, eg if stored in file
  --csoaa_rank          Return actions sorted by score order
  --probabilities       predict probabilites of all classes
Contextual Bandit with Action Dependent Features:
  --cb_adf              Do Contextual Bandit learning with multiline action 
                        dependent features.
  --rank_all            Return actions sorted by score order
  --no_predict          Do not do a prediction when training
  --clip_p arg (=0, )   Clipping probability in importance weight. Default: 0.f
                        (no clipping).
  --cb_type arg         contextual bandit method to use in {ips, dm, dr, mtr, 
                        sm}. Default: mtr
